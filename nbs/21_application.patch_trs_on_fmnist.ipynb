{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train a patch based ML model on FMNIST\n",
    "> Testing patch approaches on FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 14.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_openml(\"Fashion-MNIST\", data_home=\"/home/matthieu/sklearn_data\")\n",
    "\n",
    "X = data[\"data\"].reshape(-1,28,28)\n",
    "Y = data[\"target\"]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, train_size=60000, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlg_lib.ml_utils import PatchTransform, LambdaRow\n",
    "from mlg_lib.imgfeat import flatten\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlg_lib.ml_utils import sk_train\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    PatchTransform(transformer=make_pipeline(\n",
    "                                LambdaRow(flatten),\n",
    "                                StandardScaler(),\n",
    "                                PCA(n_components=8)\n",
    "                            ),\n",
    "               patch_size=8,\n",
    "               stride=8,\n",
    "               max_patches=10\n",
    "              ),\n",
    "    RandomForestClassifier(max_depth=None, max_features=\"log2\", n_estimators=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sk_train(xtrain, xtest, ytrain, ytest, pipeline, metrics=dict(cm=confusion_matrix, acc=accuracy_score).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingOutput(model=Pipeline(memory=None,\n",
      "         steps=[('patchtransform',\n",
      "                 PatchTransform(max_patches=10, patch_size=8, stride=8,\n",
      "                                transformer=Pipeline(memory=None,\n",
      "                                                     steps=[('lambdarow',\n",
      "                                                             LambdaRow(row_func=<function flatten at 0x7f75a09d0378>)),\n",
      "                                                            ('standardscaler',\n",
      "                                                             StandardScaler(copy=True,\n",
      "                                                                            with_mean=True,\n",
      "                                                                            with_std=True)),\n",
      "                                                            ('pca',\n",
      "                                                             PCA(copy=True,\n",
      "                                                                 iterated_power='auto',\n",
      "                                                                 n_components=8,\n",
      "                                                                 random_state...\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features='log2',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), metrics={'train_cm': array([[6019,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "       [   0, 5964,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "       [   0,    0, 5955,    0,    0,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,    0, 5988,    0,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,    0, 6028,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0, 6007,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0, 6009,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0, 6003,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0,    0, 6004,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 6023]]), 'train_acc': 1.0, 'test_cm': array([[839,   1,  18,  38,   6,   1,  64,   0,  14,   0],\n",
      "       [  5, 980,   9,  37,   2,   0,   3,   0,   0,   0],\n",
      "       [  6,   1, 847,  11, 104,   0,  72,   0,   4,   0],\n",
      "       [ 23,   7,  15, 923,  25,   0,  17,   0,   2,   0],\n",
      "       [  1,   1,  61,  48, 797,   0,  60,   0,   4,   0],\n",
      "       [  0,   0,   0,   0,   0, 945,   0,  37,   2,   9],\n",
      "       [174,   1, 122,  34,  93,   0, 554,   0,  13,   0],\n",
      "       [  0,   0,   0,   0,   0,  33,   0, 927,   2,  35],\n",
      "       [  4,   0,   7,   8,   4,   4,  10,   1, 955,   3],\n",
      "       [  0,   0,   0,   0,   0,  15,   0,  37,   0, 925]]), 'test_acc': 0.8692})\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    PatchTransform(transformer=make_pipeline(\n",
    "                                LambdaRow(flatten),\n",
    "                                RandomTreesEmbedding(max_depth=2, n_estimsklearnrs=32, sparse_output=False),\n",
    "                                TruncatedSVD(n_components=8)\n",
    "                                \n",
    "                            ),\n",
    "               patch_size=8,\n",
    "               stride=8,\n",
    "               max_patches=10\n",
    "              ),\n",
    "    RandomForestClassifier(max_depth=None, max_features=\"log2\", n_estimators=100)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
