{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ml_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml_utils\n",
    "> Utilities to use sklearn for image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "from numpy.core._multiarray_umath import ndarray\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class LambdaRow(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    \n",
    "    Apply a function on each row of the numpy array\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 row_func: Callable[[ndarray], ndarray],\n",
    "                 to_features: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Constructor for LambdaRow\"\"\"\n",
    "        self.func = row_func\n",
    "        self.func_kwargs = kwargs\n",
    "        self.to_features = to_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        _arr = np.array([self.func(x, **self.func_kwargs) for x in X])\n",
    "        if len(_arr.shape)>=2:\n",
    "            if self.to_features:\n",
    "                N = _arr.shape[0]\n",
    "                return _arr.reshape(N,-1)\n",
    "            else:\n",
    "                return _arr\n",
    "        else:\n",
    "            return _arr.reshape(-1,1)\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return dict(list(self.func_kwargs.items())+[(\"row_func\", self.func)])\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        # params.pop(\"row_func\")\n",
    "        self.func_kwargs.update(params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.randint(0,255, size=(16,32,32))\n",
    "\n",
    "LambdaRow(row_func=lambda x: x.mean()).fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import attr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Callable, Dict, Any\n",
    "\n",
    "@attr.s\n",
    "class TrainingOutput(object):\n",
    "    \n",
    "    model = attr.ib(type=Pipeline)\n",
    "    metrics = attr.ib(type=Dict[str, Any])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from typing import Callable, Dict, Any\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def sk_train(\n",
    "    xtrain: np.ndarray,\n",
    "    xtest: np.ndarray,\n",
    "    ytrain: np.ndarray,\n",
    "    ytest: np.ndarray,\n",
    "    model: Pipeline,\n",
    "    metrics: Dict[str, Callable[[np.ndarray, np.ndarray], Any]]\n",
    "    )->TrainingOutput:\n",
    "\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    computed_metrics = dict()\n",
    "\n",
    "    for tag, (x,y) in [(\"train\", (xtrain, ytrain) ), (\"test\", (xtest, ytest))]:\n",
    "        predictions = model.predict(x)\n",
    "\n",
    "        for metric_tag, metric_fn in metrics:\n",
    "            computed_metrics[\"_\".join([tag, metric_tag])] = metric_fn(y, predictions)\n",
    "    \n",
    "    return TrainingOutput(\n",
    "        model=model,\n",
    "        metrics=computed_metrics\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/anaconda2/envs/pypurr/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingOutput(model=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False), metrics={'train_acc': 0.9958, 'test_acc': 0.9596})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, Y = make_classification(10000)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, train_size=0.5)\n",
    "\n",
    "sk_train(xtrain, xtest, ytrain, ytest, RandomForestClassifier(), metrics=dict(acc=accuracy_score).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "def make_single_feature_model(\n",
    "    feature_fn: Callable[[np.ndarray], np.ndarray],\n",
    "    clf: Pipeline\n",
    "    )->Pipeline:\n",
    "\n",
    "    return make_pipeline(\n",
    "        LambdaRow(feature_fn),\n",
    "        clf\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
